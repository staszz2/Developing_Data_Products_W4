set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
qplot(training$Superplasticizer)
qplot(log(training$Superplasticizer))
summary(training$Superplasticizer)
head(training$Superplasticizer,20)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
head(training, 20
)
names(training)
x <- names(training)
IL_col_idx <- grep("^[Ii][Ll].*", names(training))
IL_col_idx
names(training[,IL_col_idx])
preObj <- preProcess(training[, IL_col_idx], method=c("center", "scale", "pca"), thresh=0.9)
proObj
preObj
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]training = adData[ inTrain,]
testing = adData[-inTrain,]
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
IL_col_idx <- grep("^[Ii][Ll].*", names(training))
preObj <- preProcess(training[, IL_col_idx], method=c("glm"), thresh=0.8)
non_pca_model <- train(diagnosis ~ ., data=new_training, method="glm")
new_testing <- testing[, c(names(testing)[IL_col_idx], "diagnosis")]
non_pca_model <- train(diagnosis ~ ., data=new_training, method="glm")
new_training <- training[, c(names(training)[IL_col_idx], "diagnosis")]
non_pca_model <- train(diagnosis ~ ., data=new_training, method="glm")
install.packages("e1071")
non_pca_model <- train(diagnosis ~ ., data=new_training, method="glm")
head(new_testing)
confusionMatrix(new_testing[, 13], predict(non_pca_model, new_testing[, -13]))
preObj <- preProcess(training[, IL_col_idx], method=c("center", "scale", "pca"), thresh=0.8)
preObj
modelFit <- train(training$diagnosis ~ .,
method="glm",
preProcess="pca",
data=training,
trControl=trainControl(preProcOptions=list(thresh=0.8)))
data(Wage)
# remove log wage variable (we are trying to predict wage)
Wage <- subset(Wage,select=-c(logwage))
# create train/test data sets
inTrain <- createDataPartition(y=Wage$wage,p=0.7, list=FALSE)
training <- Wage[inTrain,]; testing <- Wage[-inTrain,]
# run the gbm model
modFit <- train(wage ~ ., method="gbm",data=training,verbose=FALSE)
# print model summary
print(modFit)
library(ISLR)
head(Wage)
Wage <- subset(Wage,select=-c(logwage))
modFit <- train(wage ~ ., method="gbm",data=Wage,verbose=FALSE)
library(caret)
modFit <- train(wage ~ ., method="gbm",data=Wage,verbose=FALSE)
modFit <- train(wage ~ ., method="gbm",data=Wage,verbose=FALSE)
print(modFit)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
segmentationOriginal
summary(segmentationOriginal)
str(segmentationOriginal)
train <- segmentationOriginal[Case=="Train"]
train <- segmentationOriginal[segmentationOriginal$Case=="Train"]
train <- segmentationOriginal[which(Case=="Train")]
train <- segmentationOriginal[which(segmentationOriginal$Case=="Train")]
train <= subset(segmentationOriginal, segmentationOriginal$Case=="Train")
train <- subset(segmentationOriginal, segmentationOriginal$Case=="Train")
test <- subset(segmentationOriginal, segmentationOriginal$Case=="Test")
set.seed(125)
CART <- train(Class ~.,data=train,method="rpart")
pred <- predict(CART, data.frame(TotalIntench2 = 23,000; FiberWidthCh1 = 10; PerimStatusCh1=2))
pred <- predict(CART, data.frame(TotalIntench2 = 23,000, FiberWidthCh1 = 10, PerimStatusCh1=2))
modFit
CART
CART$finalModel
suppressMessages(library(rattle))
library(rpart.plot)
fancyRpartPlot(CART$finalModel)
install.packages("rattle")
suppressMessages(library(rattle))
library(rpart.plot)
fancyRpartPlot(CART$finalModel)
library(pgmm)
install.packages("ppgm")
data(olive)
library(ElemStatLearn)
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
modelSA <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl,
data = trainSA, method = "glm", family = "binomial")
missClass(testSA$chd, predict(modelSA, newdata = testSA))
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass(testSA$chd, predict(modelSA, newdata = testSA))
missClass(train$chd, predict(modelSA, newdata = testSA))
missClass(trainSA$chd, predict(modelSA, newdata = testSA))
missClass(trainSA$chd, predict(modelSA, newdata = trainSA))
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
library(randomForest)
install.packages("randomforrest")
library(devtools)
install_github("mikeasilva/blsAPI")
install.packages("devtools")
library(devtools)
install_github("mikeasilva/blsAPI")
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.test$y <- factor(vowel.test$y)
vowel.train$y <- factor(vowel.train$y)
set.seed(33833)
modelgbm <- train(y ~ ., data=vowel.train, method="gbm")
library(caret)
modelgbm <- train(y ~ ., data=vowel.train, method="gbm")
modelforest <- train(y ~ ., data=vowel.train, method="rf")
predgbm <- predict(modelgbm, vowel.test)
predforest <- predict(modelforest, vowel.test)
confusionMatrix(pred_rf, vowel.test$y)$overall[1]
confusionMatrix(predforest, vowel.test$y)
confusionMatrix(predforest, vowel.test$y)overall[1]
confusionMatrix(predforest, vowel.test$y)$overall[1]
confusionMatrix(predgbm, vowel.test$y)$overall[1]
sum(pred_rf[predDF$pred_rf == predDF$pred_gbm] == predDF$y[predDF$pred_rf == predDF$pred_gbm]) / sum(predDF$pred_rf == predDF$pred_gbm)
predDF <- data.frame(pred_rf, pred_gbm, y = vowel.test$y)
predDF <- data.frame(predforest, predgbm, y = vowel.test$y)
head(predDF)
sum(predforest[predDF$predforest == predDF$predgbm] == predDF$y[predDF$predforest == predDF$predgbm]) / sum(predDF$predforest == predDF$predgbm)
sum(predDF$predforest == predDF$predgbm)
sum(predDF$predforest)
sum(predDF$predforest >0)
sum(predDF$predforest > 0)
sum(predDF$predforest == 0 )
sum(predforest[predDF$predforest == predDF$predgbm] == predDF$y[predDF$predforest == predDF$predgbm])
head(vowel.train)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
mod_rf <- train(diagnosis ~ ., data = training, method = "rf")
mod_gbm <- train(diagnosis ~ ., data = training, method = "gbm")
mod_lda <- train(diagnosis ~ ., data = training, method = "lda")
pred_rf <- predict(mod_rf, testing)
pred_gbm <- predict(mod_gbm, testing)
pred_lda <- predict(mod_lda, testing)
predDF <- data.frame(pred_rf, pred_gbm, pred_lda, diagnosis = testing$diagnosis)
predDF <- data.frame(pred_rf, pred_gbm, pred_lda, diagnosis = testing$diagnosis)
combModFit <- train(diagnosis ~ ., method = "rf", data = predDF)
combPred <- predict(combModFit, predDF)
confusionMatrix(combPred, testing$diagnosis)$overall[1]
x <- c(1,2,1,2,1,2,1,2,2,1,2,1,2)
y <- c(1,1,1,2,1,2,1,1,2,1,2,1,2)
confusionMatrix(y,x)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
modelgbm <- train(y ~ ., data=vowel.train, method="gbm")
modelforest <- train(y ~ ., data=vowel.train, method="rf")
predgbm <- predict(modelgbm, vowel.test)
predforest <- predict(modelforest, vowel.test)
predDF <- data.frame(pred_rf, pred_gbm, y = vowel.test$y)
predDF <- data.frame(predforest, predgbm, y = vowel.test$y)
combination <- train (y ~., method = "rf", data=predDF)
confusionMatrix(predict(combination,predDF))
confusionMatrix(predict(combination,predDF),predDF$y)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[inTrain, ]
testing = concrete[-inTrain, ]
mod_lasso <- train(CompressiveStrength ~ ., data = training, method = "lasso")
library(elasticnet)
plot.enet(mod_lasso$finalModel, xvar = "penalty", use.color = TRUE)
head(concrete)
set.seed(325)
library(e1071)
mod_svm <- svm(CompressiveStrength ~ ., data = training)
pred_svm <- predict(mod_svm, testing)
accuracy(pred_svm, testing$CompressiveStrength)
confusionMatrix(pred_svm,testing$CompressiveStrength)
confusionMatrix(pred_svm,training$CompressiveStrength)
x
x[x==2]
x[x==1]
x[x>1]
x[x<1]
Wage
head(Wage)
Wage[year==2004]
Wage[Wage$year==2004]
Wage[Wage$year==2004,]
head(Wage[Wage$year==2004,],20)
clearPushBack()
source('~/GitHub/ML_project.R')
source('~/GitHub/ML_project.R')
source('~/GitHub/ML_project.R')
source('~/GitHub/ML_project.R')
source('~/GitHub/ML_project.R')
source('~/GitHub/ML_project.R')
source('~/GitHub/ML_project.R')
source('~/GitHub/ML_project.R')
source('~/GitHub/ML_project.R')
list.files(getwd())
list.files(paste(getwd(),"Github")
(paste(getwd(),"Github")
(paste(getwd(),"Github")
paste(getwd(),"Github")
paste(getwd(),"Github",sep="/")
list.files(paste(getwd(),"Github",sep="/"))
source('~/GitHub/ML_project.R')
View(trainSA)
file_testing
source('~/GitHub/ML_project.R')
source('~/GitHub/ML_project.R')
str(training)
summary(training)
source('~/GitHub/ML_project.R')
source('~/GitHub/ML_project.R')
badColumns
nzv <- nearZeroVar(training, saveMetrics=TRUE)
nzvdata <- nearZeroVar(training, saveMetrics=TRUE)
nzvdata[nzvdata$nzv==TRUE || nzvdata$zeroVar==TRUE]
nzvdata[nzvdata$nzv==TRUE]
nzvdata[nzvdata$nzv==TRUE,]
nzvdata[nzvdata$nzv==TRUE || nzvdata$zeroVar==TRUE,]
nzvdata[nzvdata$nzv==TRUE | nzvdata$zeroVar==TRUE,]
nzvdata
nzvdata[nzvdata$nzv==TRUE | nzvdata$zeroVar==TRUE,]
names(trainning)
cnames(trainning)
col(trainning)
colnames(trainning)
colnames(training)
bad_columns <- nzvdata[nzvdata$nzv==TRUE | nzvdata$zeroVar==TRUE,]
colnames(training[-bad_columns])
colnames(training[-bad_columns,])
colnames(training[-names(bad_columns)])
bad_columns
bad_columns[0]
bad_columns[,0]
bad_columns[,]
bad_columns[,1]
names(bad_columns)
class(bad_columns)
row.names(bad_columns)
bad_column_names <- row.names(bad_columns)
bad_column_names
colnames(training[-bad_column_names)])
colnames(training[,-bad_column_names)])
colnames(training[,-bad_column_names])
colnames(training[-bad_column_names])
colnames(training[-bad_column_names,])
training[,bad_column_names,drop=FALSE]
colnames(training[,bad_column_names,drop=FALSE])
colnames(training[,bad_column_names,drop=TRUE])
colnames(training[,-bad_column_names,drop=TRUE])
colnames(training[,bad_column_names,drop=TRUE])
source('~/GitHub/ML_project.R')
colnames(training)
colnames(training[,c("new_window"),drop=TRUE])
colnames(training[,c("new_window"),drop=FALSE])
colnames(training)
colnames(training[,c("new_window"),drop=FALSE])
colnames(training[,c("new_window"),drop=TRUE])
colnames(training)
source('~/GitHub/ML_project.R')
colnames(training)
source('~/GitHub/ML_project.R')
source('~/GitHub/ML_project.R')
colnames(training)
head(training)
training <- training[,-1]
head(training)
sum(is.na(training[,1]))
sum(is.na(training[,20]))
head(training[,20])
na_count <-sapply(x, function(y) sum(length(which(is.na(y)))))
na_count
na_count <-sapply(training, function(y) sum(length(which(is.na(y)))))
na_count
rows(training)
nrows(training)
nrow(training)
rows <- nrow(training)
na_count <-sapply(training, function(y) sum(length(which(is.na(y))))/rows)
na_count
source('~/GitHub/ML_project.R')
source('~/Gadget1/gadget2-plot.R')
pickTrees
pickTrees()
install.packages("googleVis")
source('~/Gadget1/gadget-googleVis.R')
plot(M)
source('~/Gadget1/gadget-googleVis2.R')
plot(G)
plot(GTM)
source('~/Gadget1/gadget-googleVis3.R')
plot(GTM)
install.packages("plotly")
library(plotly)
plot_ly(mtcars, x = wt, y = mpg, mode = "markers")
mtcars
plot_ly(mtcars, x = mtcars$wt, y = mtcars$mpg, mode = "markers")
plot_ly(mtcars, x = mtcars$wt, y = mtcars$mpg, mode = "markers", color=mtcars$disp)
plot_ly(mtcars, x = mtcars$wt, y = mtcars$mpg, mode = "markers", color=mtcars$disp, size=mtcars$hp)
plot_ly(mtcars, x = mtcars$wt, y = mtcars$mpg, mode = "markers", color=mtcars$cyl, size=mtcars$hp)
set.seed(2016-07-21)
temp <- rnorm(100, mean = 30, sd = 5)
pressue <- rnorm(100)
dtime <- 1:100
plot_ly(x = temp, y = pressue, z = dtime,
type = "scatter3d", mode = "markers", color = temp)
data("airmiles")
plot_ly(x = time(airmiles), y = airmiles)
data("airmiles")
plot_ly(x = time(airmiles), y = airmiles)
library(plotly)
library(tidyr)
library(dplyr)
data("EuStockMarkets")
stocks <- as.data.frame(EuStockMarkets) %>%
gather(index, price) %>%
mutate(time = rep(time(EuStockMarkets), 4))
plot_ly(stocks, x = time, y = price, color = index)
library(plotly)
library(tidyr)
library(dplyr)
data("EuStockMarkets")
stocks <- as.data.frame(EuStockMarkets) %>%
gather(index, price) %>%
mutate(time = rep(time(EuStockMarkets), 4))
plot_ly(stocks, x = stocks$time, y = stocks$price, color = index)
library(plotly)
library(tidyr)
library(dplyr)
data("EuStockMarkets")
stocks <- as.data.frame(EuStockMarkets) %>%
gather(index, price) %>%
mutate(time = rep(time(EuStockMarkets), 4))
plot_ly(stocks, x = stocks$time, y = stocks$price, color = stocks$index)
head(stocks,20)
terrain1 <- matrix(rnorm(100*100), nrow = 100, ncol = 100)
plot_ly(z = terrain1, type = "heatmap")
terrain2 <- matrix(sort(rnorm(100*100)), nrow = 100, ncol = 100)
plot_ly(z = terrain2, type = "surface")
source('~/Gadget1/plotly6-states-map.R')
source('~/Gadget1/plotly6-states-map.R')
source('~/Gadget1/plotly6-states-map.R')
layout(title = 'US Population in 1975', geo = map_options)
source('~/Gadget1/plotly6-states-map.R')
source('~/Gadget1/plotly6-states-map.R')
source('~/Gadget1/plotly6-states-map.R')
source('~/Gadget1/plotly6-states-map.R')
Pop
state_pop
source('~/Gadget1/plotly6-states-map.R')
source('~/Gadget1/plotly6-states-map.R')
plotly()
args(plotly)
plot_ly
source('~/Gadget1/plotly6-states-map.R')
state_pop
map_options <- list(
scope = 'usa',
projection = list(type = 'albers usa'),
showlakes = TRUE,
lakecolor = toRGB('white')
)
plot_ly(data=state_pop, z = Pop, text = hover, locations = State,
type = 'choropleth', locationmode = 'USA-states',
color = Pop, colors = 'Blues', marker = list(line = borders)) %>%
layout(title = 'US Population in 1975', geo = map_options)
plot_ly(data=state_pop, z = state_pop$Pop, text = hover, locations = State,
type = 'choropleth', locationmode = 'USA-states',
color = Pop, colors = 'Blues', marker = list(line = borders)) %>%
layout(title = 'US Population in 1975', geo = map_options)
source('~/Gadget1/plotly6-states-map.R')
plot_ly(data=state_pop, z = state_pop$Pop, text = hover, locations = state_pop$State,
plot_ly(state_pop, z = state_pop$Pop, text = state_pop$hover, locations = state_pop$State, type = 'choropleth', locationmode = 'USA-states', color = state_pop$Pop, colors = 'Blues', marker = list(line = borders)) %>% layout(title = 'US Population in 1975', geo = map_options)
source('~/Gadget1/plotly6-states-map.R')
head(stocks,20)
shiny::runApp('temp2')
install.packages("UsingR")
runApp('temp2')
install.packages("leaflet")
source('~/Gadget1/leaflet.R')
source('~/Gadget1/leaflet.R')
source('~/Gadget1/leaflet.R')
source('~/Gadget1/leaflet.R')
source('~/Gadget1/leaflet.R')
source('~/Gadget1/leaflet.R')
source('~/Gadget1/leaflet.R')
source('~/Gadget1/leaflet.R')
source('~/Gadget1/leaflet.R')
source('~/Gadget1/leaflet.R')
source('~/Gadget1/leaflet.R')
source('~/Gadget1/leaflet.R')
source('~/Gadget1/leaflet.R')
source('~/Gadget1/leaflet.R')
source('~/Gadget1/leaflet.R')
source('~/Gadget1/leaflet.R')
source('~/Gadget1/leaflet.R')
source('~/Gadget1/leaflet.R')
source('~/Gadget1/leaflet.R')
source('~/Gadget1/leaflet.R')
source('~/Gadget1/leaflet.R')
source('~/Gadget1/leaflet.R')
source('~/Gadget1/leaflet.R')
source('~/Gadget1/leaflet.R')
source('~/Gadget1/leaflet.R')
source('~/Gadget1/leaflet.R')
source('~/Gadget1/leaflet.R')
source('~/Gadget1/leaflet.R')
source('~/Gadget1/leaflet.R')
source('~/Gadget1/leaflet.R')
source('~/Gadget1/leaflet.R')
df(leaflet(addTiles()))
addTiles(leaflet(df()))
leaflet(addTiles(df))
addTiles(leaflet(df))
leaflet(df) %>% addTiles()
leaflet(addTiles(df))
df %>% leaflet() %>% addTiles()
addTiles(leaflet(df()))
addTiles(leaflet(df))
source('~/Gadget1/leaflet.R')
df <- (lat = c(1,2),lng = c(3,4))
df <- (lat = c(12),lng = c(34))
df <- (lat = c(12) lng = c(34))
source('~/Gadget1/leaflet.R')
map <- df %>%
leaflet() %>%
addTiles() %>%
addMarkers() %>%
addCircleMarkers(weight = tipping_weight, radius = electoral_size)
map
tipping_population <- c(2912941-2844705,2279210-2267373,2771984-2317001,1409467-1382210)
#this is just for graphic compability
tipping_weight <- log(tipping_population)-9
map <- df %>%
leaflet() %>%
addTiles() %>%
addMarkers() %>%
addCircleMarkers(weight = tipping_weight, radius = electoral_size)
map
electoral_size <- c(20,16,18,10)
map <- df %>%
leaflet() %>%
addTiles() %>%
addMarkers() %>%
addCircleMarkers(weight = tipping_weight, radius = electoral_size)
map
df <- data.frame(lat = c(40.786826,43.468506,40.720526,43.113987),
lng = c(-77.881001,-84.818061,-82.792258,-89.413982))
map <- df %>%
leaflet() %>%
addTiles() %>%
addMarkers() %>%
addCircleMarkers(weight = tipping_weight, radius = electoral_size)
map
shiny::runApp('GitHub/DDP/QuakePlayers')
setwd("C:\\Users\\zveres\\Documents\\GitHub\\DDP")
runApp('QuakePlayers')
runApp('QuakePlayers')
dataSet <- read.csv("players.csv")
runApp('QuakePlayers')
